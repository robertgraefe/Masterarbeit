{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = None\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# siehe Hilfscode.py\n",
    "from Hilfscode import draw_piechart\n",
    "from Hilfscode import cat_compare\n",
    "from Hilfscode import lorenz\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"random_state\" : 0,\n",
    "    \"max_iter\" : 500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = Path(r\"A:\\Workspace\\Python\\Masterarbeit\\Kaggle Home Credit Datensatz\")\n",
    "path2 = Path(r\"C:\\Users\\rober\\Documents\\Workspace\\Python\\Masterarbeit\\Kaggle Home Credit Datensatz\")\n",
    "\n",
    "if path1.is_dir():\n",
    "    DATASET_DIR = path1\n",
    "else:\n",
    "    DATASET_DIR = path2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test = pd.read_csv(DATASET_DIR / \"application_test.csv\")\n",
    "app_train = pd.read_csv(DATASET_DIR / \"application_train.csv\")\n",
    "\n",
    "description = pd.read_csv(DATASET_DIR / \"HomeCredit_columns_description.csv\", encoding=\"latin\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app_train[\"TARGET\"].replace(\n",
    "#     {\n",
    "#         0: \"Payback\",\n",
    "#         1: \"Default\"\n",
    "#     }, inplace = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payback = app_train[app_train[\"TARGET\"] == \"Payback\"]\n",
    "default = app_train[app_train[\"TARGET\"] == \"Default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = [\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train[head+ [\"TARGET\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(app_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = app_train[head + [\"TARGET\"]]\n",
    "X = X.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X[\"TARGET\"]\n",
    "x = X.drop([\"TARGET\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X)\n",
    "p = len(x.columns)\n",
    "\n",
    "r2 = reg.score(x, y)\n",
    "r2_adj = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "print(r2)\n",
    "print(r2_adj)\n",
    "print(p)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['EXT_SOURCE_2', 'EXT_SOURCE_3', 'EXT_SOURCE_1', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'AMT_GOODS_PRICE', 'DAYS_LAST_PHONE_CHANGE', 'CODE_GENDER', 'NAME_EDUCATION_TYPE', 'AMT_CREDIT', 'NAME_INCOME_TYPE', 'DAYS_ID_PUBLISH', 'FLAG_DOCUMENT_3', 'LIVINGAREA_AVG', 'REGION_RATING_CLIENT', 'APARTMENTS_AVG', 'REG_CITY_NOT_WORK_CITY', 'AMT_ANNUITY', 'FLAG_EMP_PHONE', 'DAYS_REGISTRATION', 'OCCUPATION_TYPE', 'FLOORSMAX_AVG', 'OWN_CAR_AGE', 'AMT_INCOME_TOTAL', 'REGION_POPULATION_RELATIVE', 'YEARS_BEGINEXPLUATATION_AVG', 'ORGANIZATION_TYPE', 'REG_CITY_NOT_LIVE_CITY', 'ELEVATORS_AVG', 'HOUR_APPR_PROCESS_START', 'NAME_CONTRACT_TYPE', 'FLAG_OWN_CAR', 'DEF_30_CNT_SOCIAL_CIRCLE', 'BASEMENTAREA_AVG', 'DEF_60_CNT_SOCIAL_CIRCLE', 'ENTRANCES_AVG', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'LANDAREA_AVG', 'YEARS_BUILD_AVG', 'LIVINGAPARTMENTS_AVG', 'CNT_FAM_MEMBERS', 'OBS_60_CNT_SOCIAL_CIRCLE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'CNT_CHILDREN', 'COMMONAREA_AVG', 'NONLIVINGAREA_AVG', 'AMT_REQ_CREDIT_BUREAU_QRT', 'NAME_FAMILY_STATUS', 'NONLIVINGAPARTMENTS_AVG', 'EMERGENCYSTATE_MODE', 'HOUSETYPE_MODE', 'FLOORSMIN_AVG', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'FLAG_WORK_PHONE', 'NAME_TYPE_SUITE', 'NAME_HOUSING_TYPE', 'LIVE_CITY_NOT_WORK_CITY', 'AMT_REQ_CREDIT_BUREAU_MON', 'WALLSMATERIAL_MODE', 'WEEKDAY_APPR_PROCESS_START', 'AMT_REQ_CREDIT_BUREAU_DAY', 'FLAG_PHONE', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_8', 'FONDKAPREMONT_MODE', 'FLAG_OWN_REALTY', 'FLAG_DOCUMENT_5', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'FLAG_DOCUMENT_15', 'FLAG_CONT_MOBILE', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_9', 'FLAG_EMAIL', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_21', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_13', 'FLAG_MOBIL', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_heads = ['CNT_CHILDREN','AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'TOTALAREA_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = [head for head in features if head in m_heads]\n",
    "heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        \"auc\":[],\n",
    "        \"auc_adj\":[],\n",
    "        \"p\" : [],\n",
    "        \"n\": []\n",
    "       }\n",
    "\n",
    "for t in range(len(heads)):\n",
    "    X = app_train[heads[:t+1] + [\"TARGET\"]]\n",
    "    X = X.dropna()\n",
    "    y = X[\"TARGET\"]\n",
    "    x = X.drop([\"TARGET\"], axis=1)\n",
    "    scaler = preprocessing.StandardScaler().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    model = LogisticRegression(**params).fit(x, y)\n",
    "    n = len(X)\n",
    "    p = len(X.columns)\n",
    "    \n",
    "    # unterteilt den trainingsdatensatz in trainings- und validierungsdatensätze\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, random_state=0)\n",
    "    \n",
    "    x_test_prob = model.predict_proba(x_test)\n",
    "    # Erstellung der AUC & ROC-Metrik\n",
    "    # Wahrscheinlichkeiten für keinen Kreditausfall\n",
    "    prob = x_test_prob[:,1]\n",
    "    auc = roc_auc_score(y_test, prob)\n",
    "    auc_adj = 1-(1-auc)*(n-1)/(n-p-1)\n",
    "\n",
    "    data[\"auc\"].append(auc)\n",
    "    data[\"auc_adj\"].append(auc_adj)\n",
    "    data[\"p\"].append(p)\n",
    "    data[\"n\"].append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[\"auc\"] == df[\"auc\"].max()])\n",
    "df[\"auc\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[\"auc_adj\"] == df[\"auc_adj\"].max()])\n",
    "df[\"auc_adj\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = app_train[\"TARGET\"]\n",
    "x = app_train[heads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ersätzt alle np.nan durch 0\n",
    "x = x.fillna(0)\n",
    "\n",
    "# unterteilt den trainingsdatensatz in trainings- und validierungsdatensätze\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, random_state=0)\n",
    "\n",
    "# logistisches Regressionsmodell\n",
    "model = LogisticRegression(**params)\n",
    "\n",
    "aucs = []\n",
    "\n",
    "kfold = KFold(5, True, 1)\n",
    "data = x\n",
    "\n",
    "# enumerate splits\n",
    "for i, (train, test) in enumerate(kfold.split(data)):\n",
    "    model.fit(x.loc[train], y.loc[train])\n",
    "    \n",
    "    # Prognosewerte der Testdaten in %\n",
    "    x_test_prob = model.predict_proba(x.loc[test])\n",
    "\n",
    "    # Erstellung der AUC & ROC-Metrik\n",
    "    # Wahrscheinlichkeiten für keinen Kreditausfall\n",
    "    prob = x_test_prob[:,1]\n",
    "    auc = roc_auc_score(y.loc[test], prob)\n",
    "    aucs.append(auc)\n",
    "    print('train: %s, test: %s, auc: %s' % (train, test, auc))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Durchschnitt: %.2f\" % (np.mean(aucs)))\n",
    "print(\"Standardabw.: %.2f\" % (np.std(aucs)))\n",
    "print(\"Varianz:      %.2f\" % (np.var(aucs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stammdaten + Bureaudaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = pd.read_csv(DATASET_DIR / \"bureau.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_heads = [head for head in bureau.columns if bureau[head].dtype.name != \"object\"]\n",
    "n_heads = [head for head in bureau.columns if bureau[head].dtype.name == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"SK_ID_CURR\", \"SK_ID_BUREAU\"]\n",
    "m_heads = [element for element in m_heads if element not in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for index, head in enumerate(m_heads):\n",
    "    \n",
    "    df = bureau[[\"SK_ID_CURR\", head]]\n",
    "    df = df.groupby(by = [\"SK_ID_CURR\"]).quantile(quants)\n",
    "    df = df.unstack(level=-1)\n",
    "    \n",
    "    try:\n",
    "        mets = mets.join(df , on = \"SK_ID_CURR\")\n",
    "    except (ValueError, NameError):\n",
    "        mets = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = list(mets.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = pd.merge(mets, app_train[[\"SK_ID_CURR\",\"TARGET\"]], on=\"SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = bureau.drop([\"SK_ID_CURR\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = t\n",
    "\n",
    "data = {\n",
    "        \"auc\":[],\n",
    "        \"auc_adj\":[],\n",
    "        \"p\" : [],\n",
    "        \"n\": []\n",
    "       }\n",
    "\n",
    "for q in range(len(heads)):\n",
    "    X = df[heads[:q+1] + [\"TARGET\"]]\n",
    "    X = X.dropna()\n",
    "    y = X[\"TARGET\"]\n",
    "    x = X.drop([\"TARGET\"], axis=1)\n",
    "    scaler = preprocessing.StandardScaler().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    model = LogisticRegression(**params).fit(x, y)\n",
    "    n = len(X)\n",
    "    p = len(X.columns)\n",
    "    \n",
    "    # unterteilt den trainingsdatensatz in trainings- und validierungsdatensätze\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, random_state=0)\n",
    "    \n",
    "    x_test_prob = model.predict_proba(x_test)\n",
    "    # Erstellung der AUC & ROC-Metrik\n",
    "    # Wahrscheinlichkeiten für keinen Kreditausfall\n",
    "    prob = x_test_prob[:,1]\n",
    "    auc = roc_auc_score(y_test, prob)\n",
    "    auc_adj = 1-(1-auc)*(n-1)/(n-p-1)\n",
    "\n",
    "    data[\"auc\"].append(auc)\n",
    "    data[\"auc_adj\"].append(auc_adj)\n",
    "    data[\"p\"].append(p)\n",
    "    data[\"n\"].append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[\"auc\"] == df[\"auc\"].max()])\n",
    "df[\"auc\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[\"auc_adj\"] == df[\"auc_adj\"].max()])\n",
    "df[\"auc_adj\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = t[\"TARGET\"]\n",
    "x = t.drop([\"TARGET\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ersätzt alle np.nan durch 0\n",
    "x = x.fillna(0)\n",
    "\n",
    "\n",
    "# unterteilt den trainingsdatensatz in trainings- und validierungsdatensätze\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, random_state=0)\n",
    "\n",
    "# logistisches Regressionsmodell\n",
    "model = LogisticRegression(random_state=0)\n",
    "\n",
    "aucs = []\n",
    "\n",
    "kfold = KFold(5, True, 1)\n",
    "data = x\n",
    "\n",
    "# enumerate splits\n",
    "for i, (train, test) in enumerate(kfold.split(data)):\n",
    "    model.fit(x.loc[train], y.loc[train])\n",
    "    \n",
    "    # Prognosewerte der Testdaten in %\n",
    "    x_test_prob = model.predict_proba(x.loc[test])\n",
    "\n",
    "    # Erstellung der AUC & ROC-Metrik\n",
    "    # Wahrscheinlichkeiten für keinen Kreditausfall\n",
    "    prob = x_test_prob[:,1]\n",
    "    auc = roc_auc_score(y.loc[test], prob)\n",
    "    aucs.append(auc)\n",
    "    print('train: %s, test: %s, auc: %s' % (train, test, auc))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Durchschnitt: %.2f\" % (np.mean(aucs)))\n",
    "print(\"Standardabw.: %.2f\" % (np.std(aucs)))\n",
    "print(\"Varianz:      %.2f\" % (np.var(aucs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Train & Bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_heads = ['CNT_CHILDREN','AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'TOTALAREA_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = app_train[[\"SK_ID_CURR\",\"TARGET\"] + m_heads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = bureau.drop([\"TARGET\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m.merge(bureau, on=\"SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.drop([\"SK_ID_CURR\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = t[\"TARGET\"]\n",
    "x = t.drop([\"TARGET\"], axis=1)\n",
    "\n",
    "# ersätzt alle np.nan durch 0\n",
    "x = x.fillna(0)\n",
    "\n",
    "\n",
    "# unterteilt den trainingsdatensatz in trainings- und validierungsdatensätze\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, random_state=0)\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "#model = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koeffizienten der einzelnen Klassen\n",
    "coef_dict = {}\n",
    "for coef, feat in zip(model.feature_importances_, x.columns.values):\n",
    "    coef_dict[feat] = coef\n",
    "    \n",
    "# Feature Importance\n",
    "d = dict(sorted(coef_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = list(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = t\n",
    "\n",
    "data = {\n",
    "        \"auc\":[],\n",
    "        \"auc_adj\":[],\n",
    "        \"p\" : [],\n",
    "        \"n\": []\n",
    "       }\n",
    "\n",
    "for q in range(len(heads)):\n",
    "    X = df[heads[:q+1] + [\"TARGET\"]]\n",
    "    X = X.dropna()\n",
    "    y = X[\"TARGET\"]\n",
    "    x = X.drop([\"TARGET\"], axis=1)\n",
    "    scaler = preprocessing.StandardScaler().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    model = LogisticRegression(random_state=0).fit(x, y)\n",
    "    n = len(X)\n",
    "    p = len(X.columns)\n",
    "    \n",
    "    # unterteilt den trainingsdatensatz in trainings- und validierungsdatensätze\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, random_state=0)\n",
    "    \n",
    "    x_test_prob = model.predict_proba(x_test)\n",
    "    # Erstellung der AUC & ROC-Metrik\n",
    "    # Wahrscheinlichkeiten für keinen Kreditausfall\n",
    "    prob = x_test_prob[:,1]\n",
    "    auc = roc_auc_score(y_test, prob)\n",
    "    auc_adj = 1-(1-auc)*(n-1)/(n-p-1)\n",
    "\n",
    "    data[\"auc\"].append(auc)\n",
    "    data[\"auc_adj\"].append(auc_adj)\n",
    "    data[\"p\"].append(p)\n",
    "    data[\"n\"].append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[\"auc\"] == df[\"auc\"].max()])\n",
    "df[\"auc\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[\"auc_adj\"] == df[\"auc_adj\"].max()])\n",
    "df[\"auc_adj\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = t[\"TARGET\"]\n",
    "x = t.drop([\"TARGET\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ersätzt alle np.nan durch 0\n",
    "x = x.fillna(0)\n",
    "\n",
    "# unterteilt den trainingsdatensatz in trainings- und validierungsdatensätze\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, random_state=0)\n",
    "\n",
    "# logistisches Regressionsmodell\n",
    "model = LogisticRegression(random_state=0)\n",
    "\n",
    "aucs = []\n",
    "\n",
    "kfold = KFold(5, True, 1)\n",
    "data = x\n",
    "\n",
    "# enumerate splits\n",
    "for i, (train, test) in enumerate(kfold.split(data)):\n",
    "    model.fit(x.loc[train], y.loc[train])\n",
    "    \n",
    "    # Prognosewerte der Testdaten in %\n",
    "    x_test_prob = model.predict_proba(x.loc[test])\n",
    "\n",
    "    # Erstellung der AUC & ROC-Metrik\n",
    "    # Wahrscheinlichkeiten für keinen Kreditausfall\n",
    "    prob = x_test_prob[:,1]\n",
    "    auc = roc_auc_score(y.loc[test], prob)\n",
    "    aucs.append(auc)\n",
    "    print('train: %s, test: %s, auc: %s' % (train, test, auc))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Durchschnitt: %.2f\" % (np.mean(aucs)))\n",
    "print(\"Standardabw.: %.2f\" % (np.std(aucs)))\n",
    "print(\"Varianz:      %.2f\" % (np.var(aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = list(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0\n",
    "h = []\n",
    "\n",
    "df = t\n",
    "\n",
    "data = {\n",
    "        \"auc\":[],\n",
    "        \"auc_adj\":[],\n",
    "        \"p\" : [],\n",
    "        \"n\": []\n",
    "       }\n",
    "\n",
    "for head in heads:\n",
    "    h.append(head)\n",
    "    X = df[h + [\"TARGET\"]]\n",
    "    X = X.dropna()\n",
    "    y = X[\"TARGET\"]\n",
    "    x = X.drop([\"TARGET\"], axis=1)\n",
    "    scaler = preprocessing.StandardScaler().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    model = LogisticRegression(random_state=0).fit(x, y)\n",
    "    n = len(X)\n",
    "    p = len(X.columns)\n",
    "    \n",
    "    # unterteilt den trainingsdatensatz in trainings- und validierungsdatensätze\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, random_state=0)\n",
    "    \n",
    "    x_test_prob = model.predict_proba(x_test)\n",
    "    # Erstellung der AUC & ROC-Metrik\n",
    "    # Wahrscheinlichkeiten für keinen Kreditausfall\n",
    "    prob = x_test_prob[:,1]\n",
    "    auc = roc_auc_score(y_test, prob)\n",
    "    auc_adj = 1-(1-auc)*(n-1)/(n-p-1)\n",
    "\n",
    "    if auc_adj > temp:\n",
    "\n",
    "        data[\"auc\"].append(auc)\n",
    "        data[\"auc_adj\"].append(auc_adj)\n",
    "        data[\"p\"].append(p)\n",
    "        data[\"n\"].append(n)\n",
    "        \n",
    "        temp = auc_adj\n",
    "    \n",
    "    else:\n",
    "        h.remove(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[\"auc\"] == df[\"auc\"].max()])\n",
    "df[\"auc\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df[\"auc_adj\"] == df[\"auc_adj\"].max()])\n",
    "df[\"auc_adj\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t[[\"TARGET\"] + h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = t[\"TARGET\"]\n",
    "x = t.drop([\"TARGET\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ersätzt alle np.nan durch 0\n",
    "x = x.fillna(0)\n",
    "\n",
    "# unterteilt den trainingsdatensatz in trainings- und validierungsdatensätze\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, random_state=0)\n",
    "\n",
    "# logistisches Regressionsmodell\n",
    "model = LogisticRegression(random_state=0)\n",
    "\n",
    "aucs = []\n",
    "\n",
    "kfold = KFold(5, True, 1)\n",
    "data = x\n",
    "\n",
    "# enumerate splits\n",
    "for i, (train, test) in enumerate(kfold.split(data)):\n",
    "    model.fit(x.loc[train], y.loc[train])\n",
    "    \n",
    "    # Prognosewerte der Testdaten in %\n",
    "    x_test_prob = model.predict_proba(x.loc[test])\n",
    "\n",
    "    # Erstellung der AUC & ROC-Metrik\n",
    "    # Wahrscheinlichkeiten für keinen Kreditausfall\n",
    "    prob = x_test_prob[:,1]\n",
    "    auc = roc_auc_score(y.loc[test], prob)\n",
    "    aucs.append(auc)\n",
    "    print('train: %s, test: %s, auc: %s' % (train, test, auc))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Durchschnitt: %.2f\" % (np.mean(aucs)))\n",
    "print(\"Standardabw.: %.2f\" % (np.std(aucs)))\n",
    "print(\"Varianz:      %.2f\" % (np.var(aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
